{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edcdc741-3f08-4f14-9dcb-fee35adf17b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# URL clustering based on similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058ca4fc-3688-4b17-959c-52ecc00c4f64",
   "metadata": {},
   "source": [
    "- urls_df = full dataset\n",
    "- urls_tdf = full dataset transformed\n",
    "- urls_tsdf = sampled dataset transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4ea9e-cbfd-40bf-8edf-1e5f7d0c249a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c099e27e-3bc4-4243-866d-9fd3a6c9acd7",
   "metadata": {},
   "source": [
    "### Save or load jupyter session"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52be716f-a093-4e01-9436-092fcaef2232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T16:57:20.270196Z",
     "iopub.status.busy": "2023-04-28T16:57:20.269345Z",
     "iopub.status.idle": "2023-04-28T16:57:21.985755Z",
     "shell.execute_reply": "2023-04-28T16:57:21.976144Z",
     "shell.execute_reply.started": "2023-04-28T16:57:20.270156Z"
    },
    "tags": []
   },
   "source": [
    "# Save\n",
    "import datetime\n",
    "\n",
    "import dill\n",
    "\n",
    "SESSION_DIR = \"jupyter_sessions\"\n",
    "PREFIX = datetime.datetime.now()\n",
    "SUFFIX = \"\"\n",
    "\n",
    "file_path = (\n",
    "    f'{SESSION_DIR}/{datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")}{SUFFIX}.db'\n",
    ")\n",
    "dill.detect.trace(False)\n",
    "dill.dump_session(file_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aef9c046-8396-4084-9add-2ccc04f470f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T09:21:18.349024Z",
     "iopub.status.busy": "2023-04-15T09:21:18.348591Z",
     "iopub.status.idle": "2023-04-15T09:21:25.275127Z",
     "shell.execute_reply": "2023-04-15T09:21:25.273506Z",
     "shell.execute_reply.started": "2023-04-15T09:21:18.348992Z"
    },
    "tags": []
   },
   "source": [
    "# Load\n",
    "import dill\n",
    "\n",
    "SESSION_DIR = \"jupyter_sessions\"\n",
    "FILE_NAME = \"20230414203732\"\n",
    "\n",
    "dill.load_session(f\"{SESSION_DIR}/{FILE_NAME}.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b302250-f8da-4335-9c4a-41b1fff31c4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7329734-9b2a-41ec-ba43-4c2246c6028b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T19:59:36.469215Z",
     "iopub.status.busy": "2023-04-29T19:59:36.468853Z",
     "iopub.status.idle": "2023-04-29T19:59:36.858594Z",
     "shell.execute_reply": "2023-04-29T19:59:36.852606Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.469174Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster, linkage\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import smaz\n",
    "import tldextract\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import (\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer, OneHotEncoder, StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce0e782-dc96-40ee-878f-6d775b345fae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e59872-2310-43fe-8f89-575c357cea0c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.859582Z",
     "iopub.status.idle": "2023-04-29T19:59:36.860040Z",
     "shell.execute_reply": "2023-04-29T19:59:36.859835Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.859810Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from polyleven import levenshtein\n",
    "\n",
    "\n",
    "def levenshtein_pdist(u, v):\n",
    "    if isinstance(u, np.ndarray):\n",
    "        u = u[0]\n",
    "    if isinstance(v, np.ndarray):\n",
    "        v = v[0]\n",
    "    return levenshtein(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e78c63-2f12-42c7-be48-27906861093c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b9602-bb8e-4b73-997e-f956b13c4a89",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.861194Z",
     "iopub.status.idle": "2023-04-29T19:59:36.861765Z",
     "shell.execute_reply": "2023-04-29T19:59:36.861537Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.861511Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_df = pd.read_csv(\n",
    "    \"datasets/kaggle_siddharta_malicious_benign.csv\",\n",
    "    delimiter=\",\",\n",
    "    dtype={\"url\": \"string\"},\n",
    ")\n",
    "\n",
    "urls_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2adb08b-bb91-471f-bcf2-d1a92e264613",
   "metadata": {},
   "source": [
    "### Extract domain names from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e54d8-b7ac-44fe-b325-20aefb639215",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.863163Z",
     "iopub.status.idle": "2023-04-29T19:59:36.863608Z",
     "shell.execute_reply": "2023-04-29T19:59:36.863395Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.863369Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Regex pattern to extract fully qualified domain name (FQDN)\n",
    "pattern = r\"(?:.*?:\\/\\/)?(?P<www>[wW]{3}\\.)?(?P<domain>[\\w\\.\\-]+)[^\\w]*\"\n",
    "\n",
    "# Execute regex over URLs\n",
    "match = urls_df[\"url\"].str.extract(pattern)\n",
    "\n",
    "# Extract domain using named group\n",
    "urls_df[\"FQDN\"] = match[\"domain\"]\n",
    "\n",
    "# Indicate if www subdomain is present\n",
    "urls_df[\"has_www\"] = match[\"www\"].notna()\n",
    "\n",
    "urls_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa406c1f-e1d6-4b6a-a74a-f920b325d65d",
   "metadata": {},
   "source": [
    "### Remove all addreses without domain (IPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf3dca-9569-4dd8-8753-40e2070b994d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.864856Z",
     "iopub.status.idle": "2023-04-29T19:59:36.865292Z",
     "shell.execute_reply": "2023-04-29T19:59:36.865088Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.865064Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pattern that matches all IPv4 addresses\n",
    "pattern = \"(?:.*?:\\/\\/)?(?P<www>[wW]{3}\\.)?[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}([/:].*)?$\"\n",
    "\n",
    "# Leave only data not containing pure IPv4\n",
    "urls_df = urls_df[~urls_df[\"url\"].str.match(pattern)]\n",
    "\n",
    "# Reset index\n",
    "urls_df = urls_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2613b8-eacf-478e-8f89-5702759d2b5f",
   "metadata": {},
   "source": [
    "### Extract features from domains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71886ded-a5f4-4d64-aad8-f007a6e52056",
   "metadata": {},
   "source": [
    "#### Separate TLD, domain and subdomain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729e738-9a2c-4b55-a736-4d6914996182",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.866569Z",
     "iopub.status.idle": "2023-04-29T19:59:36.867178Z",
     "shell.execute_reply": "2023-04-29T19:59:36.866972Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.866946Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to extract components of domain using tldextract\n",
    "def extract_domain_components(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    return pd.Series([ext.subdomain, ext.domain, ext.suffix, ext.suffix == \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0ac75-2e2f-406a-ab69-d30e86021b23",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.868844Z",
     "iopub.status.idle": "2023-04-29T19:59:36.869283Z",
     "shell.execute_reply": "2023-04-29T19:59:36.869080Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.869055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply function to url column to extract domain components and explode into separate columns\n",
    "urls_df[[\"subdomain\", \"domain\", \"TLD\", \"is_invalid_TLD\"]] = urls_df[\"url\"].apply(\n",
    "    extract_domain_components\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f473f-7144-4b97-b2c7-71c445d7d838",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.870689Z",
     "iopub.status.idle": "2023-04-29T19:59:36.871322Z",
     "shell.execute_reply": "2023-04-29T19:59:36.871098Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.871073Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_df[urls_df[\"is_invalid_TLD\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12e0b0-5436-4cbb-9f82-e2501ced55ed",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.872719Z",
     "iopub.status.idle": "2023-04-29T19:59:36.873482Z",
     "shell.execute_reply": "2023-04-29T19:59:36.873274Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.873248Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove domains with invalid TLD\n",
    "urls_df = urls_df[~urls_df[\"is_invalid_TLD\"]]\n",
    "\n",
    "# Reset index\n",
    "urls_df = urls_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e55e0f-bbe2-4e48-ae4b-aaad5cbbd180",
   "metadata": {},
   "source": [
    "#### Length of domain, subdomain and TLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a7d8e-ade3-423b-8ca8-44b45211b27f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.874623Z",
     "iopub.status.idle": "2023-04-29T19:59:36.875164Z",
     "shell.execute_reply": "2023-04-29T19:59:36.874952Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.874927Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_df[[\"domain_length\", \"subdomain_length\", \"TLD_length\"]] = urls_df[\n",
    "    [\"domain\", \"subdomain\", \"TLD\"]\n",
    "].applymap(len)\n",
    "urls_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38a566b-c1e8-4c07-846f-aab069e6650c",
   "metadata": {},
   "source": [
    "#### Number of subdomains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29043be7-fdfb-4d27-8eba-2d9faf59258e",
   "metadata": {},
   "source": [
    "I decide to include www in the count of subdomains. Might make performance-wise issues later. Reconsider if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9d70b-c3d1-4852-b36f-22b55eb9ccb5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.876719Z",
     "iopub.status.idle": "2023-04-29T19:59:36.877461Z",
     "shell.execute_reply": "2023-04-29T19:59:36.877251Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.877226Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_df[\"num_of_subdomains\"] = (\n",
    "    urls_df[\"subdomain\"].str.split(\".\").apply(lambda x: len(x) if x != [\"\"] else 0)\n",
    ")\n",
    "urls_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77a85a-a10a-46df-b0af-c5457763a742",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Characters frequency & vowel-to-consonant ratio\n",
    "Characters:\n",
    "- alphabetical - \"a-zA-Z\"\n",
    "- digits - \"0-9\"\n",
    "- special - all except alphabetical, digits and dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46d6124-1ddd-49fa-baa0-c4b6130b5de8",
   "metadata": {},
   "source": [
    "Can be changed based on the occurences of dots. It may be better to remove dots so this information is uncorrelated with num_of_substrings\n",
    "\n",
    "Try the result with and without dots to analyze the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf9cce-7888-493e-a41d-b0f9efa82ea6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.878486Z",
     "iopub.status.idle": "2023-04-29T19:59:36.879028Z",
     "shell.execute_reply": "2023-04-29T19:59:36.878820Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.878795Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in [\"domain\", \"subdomain\", \"TLD\"]:\n",
    "    # Vowel-to-consonant ratio\n",
    "    vowel_counts = urls_df[column].str.count(r\"[aeiouAEIOU]\")\n",
    "    consonant_counts = urls_df[column].str.count(r\"[b-df-hj-np-tv-zB-DF-HJ-NP-TV-Z]\")\n",
    "\n",
    "    # Get alphabetical, numeric and special character counts for specific column\n",
    "    numeric_counts = urls_df[column].str.count(r\"[0-9]\")\n",
    "    special_counts = urls_df[column].str.count(r\"[^A-Za-z0-9\\s\\.]\")\n",
    "    alpha_counts = vowel_counts + consonant_counts\n",
    "\n",
    "    # Add them into DF\n",
    "    urls_df[\n",
    "        [\n",
    "            f\"{column}_alpha_count\",\n",
    "            f\"{column}_numeric_count\",\n",
    "            f\"{column}_special_count\",\n",
    "            f\"{column}_vowel_consonant_ratio\",\n",
    "        ]\n",
    "    ] = pd.Series(\n",
    "        [alpha_counts, numeric_counts, special_counts, vowel_counts / consonant_counts]\n",
    "    )\n",
    "\n",
    "urls_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e90de86-c431-4d0d-b8e4-596d678bce9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Complexity of domain and subdomain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff41ad3-a441-4f0b-9bfe-567562ce3cea",
   "metadata": {},
   "source": [
    "Using compression algorithm (`smaz` python implementation) to approximate Kolmogorov complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ebd10c-e481-42ad-917f-d15009326d08",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.880872Z",
     "iopub.status.idle": "2023-04-29T19:59:36.881744Z",
     "shell.execute_reply": "2023-04-29T19:59:36.881381Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.881339Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_df[[\"domain_complexity\", \"subdomain_complexity\"]] = urls_df[\n",
    "    [\"domain\", \"subdomain\"]\n",
    "].applymap(lambda s: len(smaz.compress(s)) / len(s) if s != \"\" else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a1fa3-6e3b-4403-a2e8-8245cb9705e5",
   "metadata": {},
   "source": [
    "### Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b8d2e-6003-4edc-aab4-810e828934fd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.883305Z",
     "iopub.status.idle": "2023-04-29T19:59:36.884034Z",
     "shell.execute_reply": "2023-04-29T19:59:36.883698Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.883658Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create OneHotEncoded features from type\n",
    "\n",
    "\n",
    "ohenc = OneHotEncoder(sparse_output=False)\n",
    "type_ohenc = pd.DataFrame(\n",
    "    ohenc.fit_transform(urls_df[\"type\"].values.reshape(-1, 1)),\n",
    "    columns=ohenc.categories_[0],\n",
    ").astype(bool)\n",
    "\n",
    "# URLs_transformed df\n",
    "urls_tdf = pd.concat([urls_df, type_ohenc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db10b2d-9b34-4634-baf4-7a037ae25cd8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.886275Z",
     "iopub.status.idle": "2023-04-29T19:59:36.887006Z",
     "shell.execute_reply": "2023-04-29T19:59:36.886673Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.886633Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_tdf[\"malicious\"] = ~urls_tdf[\"benign\"]\n",
    "urls_tdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb44c8-67ba-41b6-9018-73373469ca58",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fad5fa-194d-46c2-b89e-b4857989464a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Incremental wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7aa504-e0a1-4712-8c36-bc19b89cedd3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.889051Z",
     "iopub.status.idle": "2023-04-29T19:59:36.889737Z",
     "shell.execute_reply": "2023-04-29T19:59:36.889410Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.889372Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IncrementalTfidf:\n",
    "    \"\"\"\n",
    "    A class to process text data in chunks and incrementally compute character-level TF-IDF values.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    hashing_vectorizer : HashingVectorizer\n",
    "        Vectorizer that converts text data to a term-document matrix using the hashing trick\n",
    "    tfidf_transformer : TfidfTransformer\n",
    "        Transformer that computes TF-IDF values from the term-document matrix\n",
    "    X_counts : scipy.sparse matrix\n",
    "        Accumulated term-document matrix\n",
    "    X_tfidf : scipy.sparse matrix\n",
    "        Accumulated TF-IDF representation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ngram_range=(1, 1),\n",
    "        n_features=2**20,\n",
    "    ):  # Default value for n_features in HashingVectorizer\n",
    "        \"\"\"\n",
    "        Initializes the IncrementalTfidf with a HashingVectorizer and TfidfTransformer.\n",
    "        \"\"\"\n",
    "        self.hashing_vectorizer = HashingVectorizer(\n",
    "            analyzer=\"char\",\n",
    "            token_pattern=None,\n",
    "            n_features=n_features,\n",
    "            ngram_range=ngram_range,\n",
    "        )\n",
    "        self.tfidf_transformer = TfidfTransformer()\n",
    "        self.X_counts = None\n",
    "        self.X_tfidf = None\n",
    "\n",
    "    def update_tf_counts(self, chunk):\n",
    "        \"\"\"\n",
    "        Updates the term-document matrix with the new chunk of text data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        chunk : pandas.Series or list of str\n",
    "            New chunk of text data\n",
    "        \"\"\"\n",
    "        # Transform the chunk of text data into a term-document matrix using the HashingVectorizer\n",
    "        chunk_counts = self.hashing_vectorizer.transform(chunk)\n",
    "\n",
    "        # If this is the first chunk, set the term-document matrix to the transformed chunk\n",
    "        if self.X_counts is None:\n",
    "            self.X_counts = chunk_counts\n",
    "        else:\n",
    "            # Otherwise, stack the transformed chunk to the existing term-document matrix\n",
    "            self.X_counts = sp.vstack((self.X_counts, chunk_counts))\n",
    "\n",
    "    def update_idf(self):\n",
    "        \"\"\"\n",
    "        Updates the TfidfTransformer based on the current term-document matrix.\n",
    "        \"\"\"\n",
    "        self.tfidf_transformer.fit(self.X_counts)\n",
    "\n",
    "    def partial_fit(self, chunk):\n",
    "        \"\"\"\n",
    "        Updates the term-document matrix and fits the TfidfTransformer with the new chunk of text data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        chunk : pandas.Series or list of str\n",
    "            New chunk of text data\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        self : IncrementalTfidf\n",
    "            The instance of the IncrementalTfidf\n",
    "        \"\"\"\n",
    "        self.update_tf_counts(chunk)\n",
    "        self.update_idf()\n",
    "        return self\n",
    "\n",
    "    def transform(self, chunk):\n",
    "        \"\"\"\n",
    "        Transforms the given chunk of text data to a TF-IDF representation.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        chunk : pandas.Series or list of str\n",
    "            Chunk of text data to be transformed\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chunk_tfidf : scipy.sparse matrix\n",
    "            Transformed chunk in TF-IDF representation\n",
    "        \"\"\"\n",
    "        chunk_counts = self.hashing_vectorizer.transform(chunk)\n",
    "        chunk_tfidf = self.tfidf_transformer.transform(chunk_counts)\n",
    "        return chunk_tfidf\n",
    "\n",
    "    def partial_fit_transform(self, chunk):\n",
    "        \"\"\"\n",
    "        Updates the term-document matrix, fits the TfidfTransformer, and transforms the given chunk of text data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        chunk : pandas.Series or list of str\n",
    "            New chunk of text data\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        chunk_tfidf : scipy.sparse matrix\n",
    "            Transformed chunk in TF-IDF representation\n",
    "        \"\"\"\n",
    "        self.partial_fit(chunk)\n",
    "        return self.transform(chunk)\n",
    "\n",
    "    def compute_tfidf(self):\n",
    "        \"\"\"\n",
    "        Retrieves the accumulated TF-IDF representation of the processed text data.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        X_tfidf : scipy.sparse matrix\n",
    "            Accumulated TF-IDF representation\n",
    "        \"\"\"\n",
    "        self.X_tfidf = self.tfidf_transformer.transform(self.X_counts)\n",
    "        return self.X_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31192309-f83c-41a4-966a-932f15500320",
   "metadata": {},
   "source": [
    "#### The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a7f00-734a-4331-b43f-94c9bed725ec",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.891634Z",
     "iopub.status.idle": "2023-04-29T19:59:36.892326Z",
     "shell.execute_reply": "2023-04-29T19:59:36.892008Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.891970Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NGRAM_RANGE = (1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b901b-318f-4106-832a-b567e9a67977",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.894937Z",
     "iopub.status.idle": "2023-04-29T19:59:36.895768Z",
     "shell.execute_reply": "2023-04-29T19:59:36.895430Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.895390Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "incremental_domain_tfidf = IncrementalTfidf(ngram_range=NGRAM_RANGE)\n",
    "incremental_subdomain_tfidf = IncrementalTfidf(ngram_range=NGRAM_RANGE)\n",
    "\n",
    "incremental_domain_tfidf.partial_fit(urls_df[\"domain\"])\n",
    "incremental_subdomain_tfidf.partial_fit(urls_df[\"subdomain\"])\n",
    "\n",
    "# Retrieve the accumulated TF-IDF representation\n",
    "X_domain_tfidf = incremental_domain_tfidf.compute_tfidf()\n",
    "X_subdomain_tfidf = incremental_subdomain_tfidf.compute_tfidf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4898e723-cc0c-495e-99d6-61c69533fc71",
   "metadata": {},
   "source": [
    "### Feature selection & scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f572d9-0dd6-476d-a0ef-dcb2ddc81b61",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### TF-IDF selection parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c79e3-3daf-404d-a8a9-51c5b5052f2a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.897906Z",
     "iopub.status.idle": "2023-04-29T19:59:36.898532Z",
     "shell.execute_reply": "2023-04-29T19:59:36.898237Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.898203Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the file in binary mode\n",
    "with open(\"domain_n_components_search.pkl\", \"rb\") as file:\n",
    "    components_variance_time_d = pickle.load(file)\n",
    "\n",
    "with open(\"subdomain_n_components_search.pkl\", \"rb\") as file:\n",
    "    components_variance_time_s = pickle.load(file)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69ac3dbc-9633-4226-b3ed-5038592c4981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T12:33:53.552384Z",
     "iopub.status.busy": "2023-04-29T12:33:53.552116Z",
     "iopub.status.idle": "2023-04-29T12:33:53.559472Z",
     "shell.execute_reply": "2023-04-29T12:33:53.558642Z",
     "shell.execute_reply.started": "2023-04-29T12:33:53.552351Z"
    },
    "tags": []
   },
   "source": [
    "# Open the file in binary mode\n",
    "with open(\"explained_variance_ratios.pkl\", \"rb\") as file:\n",
    "\n",
    "    # Call load method to deserialze\n",
    "    explained_variance_ratios = pickle.load(file)\n",
    "\n",
    "    print(explained_variance_ratios)\n",
    "\n",
    "with open(\"times.pkl\", \"rb\") as file:\n",
    "\n",
    "    # Call load method to deserialze\n",
    "    times = pickle.load(file)\n",
    "\n",
    "    print(times)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db603616-7c71-4847-8529-7ec0826ea03a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T12:33:53.560915Z",
     "iopub.status.busy": "2023-04-29T12:33:53.560658Z",
     "iopub.status.idle": "2023-04-29T12:33:53.565410Z",
     "shell.execute_reply": "2023-04-29T12:33:53.564608Z",
     "shell.execute_reply.started": "2023-04-29T12:33:53.560880Z"
    },
    "tags": []
   },
   "source": [
    "dt = np.dtype(\"int,float\")\n",
    "\n",
    "n_components = np.asarray(times, dtype=\"i,f\")[\"f0\"]\n",
    "\n",
    "times_explained_variance = np.dstack((n_components, explained_variance_ratios))[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c9e3fb3-243f-4c44-aef0-d9a1600fd054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T13:11:11.967051Z",
     "iopub.status.busy": "2023-04-29T13:11:11.966144Z",
     "iopub.status.idle": "2023-04-29T13:11:11.974383Z",
     "shell.execute_reply": "2023-04-29T13:11:11.972776Z",
     "shell.execute_reply.started": "2023-04-29T13:11:11.966982Z"
    },
    "tags": []
   },
   "source": [
    "# Run to remove all collected data from TruncatedSVD analysis\n",
    "del components_variance_time_d\n",
    "del components_variance_time_s"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b422b9f9-df5d-44d4-8741-b7dfaba6de15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T14:32:13.140431Z",
     "iopub.status.busy": "2023-04-29T14:32:13.139694Z",
     "iopub.status.idle": "2023-04-29T15:08:28.654859Z",
     "shell.execute_reply": "2023-04-29T15:08:28.652422Z",
     "shell.execute_reply.started": "2023-04-29T14:32:13.140363Z"
    },
    "tags": []
   },
   "source": [
    "# Calculate the explained variance ratio for different numbers of components\n",
    "# Take subsample\n",
    "SAMPLE_SIZE = int(X_domain_tfidf.shape[0] / 100)\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "random_indices = np.random.choice(\n",
    "    X_domain_tfidf.shape[0], size=SAMPLE_SIZE, replace=False\n",
    ")\n",
    "\n",
    "X_domain_tfidf_sample = X_domain_tfidf[random_indices, :]\n",
    "\n",
    "# Define search space\n",
    "start_n_components_domain = 50\n",
    "max_n_components_domain = 500\n",
    "step_domain = 50\n",
    "\n",
    "# Create DataFrame for results if it does not exist\n",
    "try:\n",
    "    components_variance_time_d\n",
    "except NameError:\n",
    "    components_variance_time_d = pd.DataFrame(\n",
    "        columns=[\"n_components\", \"explained_variance\", \"time\"]\n",
    "    )\n",
    "\n",
    "\n",
    "# Train TruncatedSVD and store results\n",
    "for n_components in range(\n",
    "    start_n_components_domain, max_n_components_domain + 1, step_domain\n",
    "):\n",
    "    start = time.time()\n",
    "    lsa = make_pipeline(TruncatedSVD(n_components=n_components), Normalizer(copy=False))\n",
    "    lsa.fit_transform(X_domain_tfidf_sample)\n",
    "    explained_variance_ratio = lsa[0].explained_variance_ratio_.sum()\n",
    "    end = time.time()\n",
    "    components_variance_time_d.loc[len(components_variance_time_d)] = (\n",
    "        n_components,\n",
    "        explained_variance_ratio,\n",
    "        end - start,\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a71c2148-4ef1-4581-894e-c6395e9b5bcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T15:22:14.453085Z",
     "iopub.status.busy": "2023-04-29T15:22:14.452639Z",
     "iopub.status.idle": "2023-04-29T15:22:14.472477Z",
     "shell.execute_reply": "2023-04-29T15:22:14.471024Z",
     "shell.execute_reply.started": "2023-04-29T15:22:14.453020Z"
    },
    "tags": []
   },
   "source": [
    "components_variance_time_d"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95245ed4-d1f3-41e5-a0d4-806751a77bd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T15:30:14.346816Z",
     "iopub.status.busy": "2023-04-29T15:30:14.346064Z",
     "iopub.status.idle": "2023-04-29T16:00:52.901475Z",
     "shell.execute_reply": "2023-04-29T16:00:52.898117Z",
     "shell.execute_reply.started": "2023-04-29T15:30:14.346754Z"
    },
    "tags": []
   },
   "source": [
    "# Calculate the explained variance ratio for different numbers of components\n",
    "# Take subsample\n",
    "SAMPLE_SIZE = int(X_subdomain_tfidf.shape[0] / 10)\n",
    "\n",
    "np.random.seed(321)\n",
    "\n",
    "random_indices = np.random.choice(\n",
    "    X_subdomain_tfidf.shape[0], size=SAMPLE_SIZE, replace=False\n",
    ")\n",
    "\n",
    "X_subdomain_tfidf_sample = X_subdomain_tfidf[random_indices, :]\n",
    "\n",
    "start_n_components_subdomain = 300\n",
    "max_n_components_subdomain = 500\n",
    "step_subdomain = 50\n",
    "\n",
    "try:\n",
    "    components_variance_time_s\n",
    "except NameError:\n",
    "    components_variance_time_s = pd.DataFrame(\n",
    "        columns=[\"n_components\", \"explained_variance\", \"time\"]\n",
    "    )\n",
    "\n",
    "for n_components in range(\n",
    "    start_n_components_subdomain, max_n_components_subdomain + 1, step_subdomain\n",
    "):\n",
    "    start = time.time()\n",
    "    lsa = make_pipeline(TruncatedSVD(n_components=n_components), Normalizer(copy=False))\n",
    "    lsa.fit_transform(X_subdomain_tfidf_sample)\n",
    "    explained_variance_ratio = lsa[0].explained_variance_ratio_.sum()\n",
    "    end = time.time()\n",
    "    components_variance_time_s.loc[len(components_variance_time_s)] = (\n",
    "        n_components,\n",
    "        explained_variance_ratio,\n",
    "        end - start,\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cfa00cf7-b7a4-4708-b4c3-98a8d6f83cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T16:00:59.301841Z",
     "iopub.status.busy": "2023-04-29T16:00:59.301098Z",
     "iopub.status.idle": "2023-04-29T16:00:59.326131Z",
     "shell.execute_reply": "2023-04-29T16:00:59.324632Z",
     "shell.execute_reply.started": "2023-04-29T16:00:59.301778Z"
    },
    "tags": []
   },
   "source": [
    "components_variance_time_d = components_variance_time_d.sort_values(\n",
    "    \"n_components\"\n",
    ").reset_index(drop=True)\n",
    "components_variance_time_d"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5aa850c-d136-4312-bbdb-3dcd1badbf54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T16:01:01.177121Z",
     "iopub.status.busy": "2023-04-29T16:01:01.176799Z",
     "iopub.status.idle": "2023-04-29T16:01:01.188694Z",
     "shell.execute_reply": "2023-04-29T16:01:01.187683Z",
     "shell.execute_reply.started": "2023-04-29T16:01:01.177087Z"
    },
    "tags": []
   },
   "source": [
    "components_variance_time_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6299d-9fee-4c9a-94f1-e291065195a5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.900464Z",
     "iopub.status.idle": "2023-04-29T19:59:36.901254Z",
     "shell.execute_reply": "2023-04-29T19:59:36.900951Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.900914Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "components_variance_time_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37849f9-9f2d-47de-9526-94407307313d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.903601Z",
     "iopub.status.idle": "2023-04-29T19:59:36.904349Z",
     "shell.execute_reply": "2023-04-29T19:59:36.904003Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.903961Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "components_variance_time_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a7a21-c64d-44b6-8b94-cc44cd9b9621",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.910368Z",
     "iopub.status.idle": "2023-04-29T19:59:36.911182Z",
     "shell.execute_reply": "2023-04-29T19:59:36.910846Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.910806Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the cumulative explained variance ratio as a function of the number of components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    components_variance_time_d[\"n_components\"],\n",
    "    components_variance_time_d[\"explained_variance\"],\n",
    "    marker=\"o\",\n",
    ")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance Ratio\")\n",
    "plt.title(\"Explained Variance Ratio vs Number of Components - Domains\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736fa4e6-5a8b-4ff3-b57f-65979b8839a8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.913432Z",
     "iopub.status.idle": "2023-04-29T19:59:36.914249Z",
     "shell.execute_reply": "2023-04-29T19:59:36.913911Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.913871Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the cumulative explained variance ratio as a function of the number of components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    components_variance_time_s[\"n_components\"],\n",
    "    components_variance_time_s[\"explained_variance\"],\n",
    "    marker=\"o\",\n",
    ")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance Ratio\")\n",
    "plt.title(\"Explained Variance Ratio vs Number of Components - Subdomains\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ecd5e-47d9-4461-9837-e6ca93aee1a8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.916406Z",
     "iopub.status.idle": "2023-04-29T19:59:36.917180Z",
     "shell.execute_reply": "2023-04-29T19:59:36.916863Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.916824Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the file in binary mode\n",
    "with open(\"domain_n_components_search.pkl\", \"wb\") as file:\n",
    "    pickle.dump(components_variance_time_d, file)\n",
    "\n",
    "with open(\"subdomain_n_components_search.pkl\", \"wb\") as file:\n",
    "    pickle.dump(components_variance_time_s, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b13b77-2a13-4ad6-930c-e02b681f4bcf",
   "metadata": {},
   "source": [
    "#### Non-TF-IDF feature imputation, scaling & selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c91f6e-101c-4e77-bf30-a266a0cd1a6a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.919065Z",
     "iopub.status.idle": "2023-04-29T19:59:36.919779Z",
     "shell.execute_reply": "2023-04-29T19:59:36.919446Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.919408Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_df_imputed = urls_df.copy()\n",
    "\n",
    "# Replace NaN values with zeros\n",
    "urls_df_imputed.fillna(0, inplace=True)\n",
    "\n",
    "# Replace infinities with the maximum finite value in each column\n",
    "urls_df_imputed = urls_df_imputed.replace([np.inf, -np.inf], np.nan)\n",
    "max_values = urls_df_imputed.max()\n",
    "urls_df_imputed.fillna(max_values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d667f1-824f-4f1c-887e-7dd3743d5e11",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.922111Z",
     "iopub.status.idle": "2023-04-29T19:59:36.922820Z",
     "shell.execute_reply": "2023-04-29T19:59:36.922487Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.922450Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ssc = StandardScaler()\n",
    "\n",
    "urls_df_relevant_scaled = ssc.fit_transform(urls_df_imputed.iloc[:, 8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8484cf15-a5d2-4cce-af50-cd28dda63aff",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.924975Z",
     "iopub.status.idle": "2023-04-29T19:59:36.925988Z",
     "shell.execute_reply": "2023-04-29T19:59:36.925663Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.925611Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "urls_df_relevant_selected = pca.fit_transform(urls_df_relevant_scaled)\n",
    "\n",
    "urls_df_relevant_sparse = sp.csr_matrix(urls_df_relevant_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39506bc3-f06a-4bd5-bc15-3bfea841ac95",
   "metadata": {},
   "source": [
    "#### TF-IDF feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c71d8b-266f-4039-adf7-64dffcc88d5c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.928088Z",
     "iopub.status.idle": "2023-04-29T19:59:36.928742Z",
     "shell.execute_reply": "2023-04-29T19:59:36.928426Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.928390Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Taken from https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html#performing-dimensionality-reduction-using-lsa\n",
    "\n",
    "lsa_domain = make_pipeline(TruncatedSVD(n_components=350), Normalizer(copy=False))\n",
    "lsa_subdomain = make_pipeline(TruncatedSVD(n_components=300), Normalizer(copy=False))\n",
    "\n",
    "X_domain_lsa = lsa_domain.fit_transform(X_domain_tfidf)\n",
    "explained_variance_d = lsa_domain[0].explained_variance_ratio_.sum()\n",
    "\n",
    "X_subdomain_lsa = lsa_subdomain.fit_transform(X_subdomain_tfidf)\n",
    "explained_variance_s = lsa_subdomain[0].explained_variance_ratio_.sum()\n",
    "\n",
    "print(\n",
    "    f\"Explained variance of domain in the SVD step: {explained_variance_d * 100:.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Explained variance of subdomain in the SVD step: {explained_variance_s * 100:.1f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3f087-6e5b-4cce-83f6-a37f71b17933",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.931226Z",
     "iopub.status.idle": "2023-04-29T19:59:36.931893Z",
     "shell.execute_reply": "2023-04-29T19:59:36.931573Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.931537Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = sp.hstack((urls_df_relevant_sparse, X_domain_lsa, X_subdomain_lsa), format=\"csr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23ec26-1d75-4d26-b45a-99c425d58e1f",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c2086-25bb-4870-88cd-d10dc6b68f99",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.933765Z",
     "iopub.status.idle": "2023-04-29T19:59:36.934540Z",
     "shell.execute_reply": "2023-04-29T19:59:36.934221Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.934184Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 40000\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "random_indices = np.random.choice(X.shape[0], size=SAMPLE_SIZE, replace=False)\n",
    "\n",
    "X_subset = X[random_indices]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "807a40a0-d4a5-492f-949f-67f082d66725",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "tsvd = IncrementalPCA(n_components=100)\n",
    "\n",
    "tsvd.fit(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0f056-5a93-4d7e-8c06-02030f84e534",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.937036Z",
     "iopub.status.idle": "2023-04-29T19:59:36.937750Z",
     "shell.execute_reply": "2023-04-29T19:59:36.937440Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.937404Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a BIRCH clustering instance\n",
    "birch_clustering = Birch(n_clusters=None)\n",
    "\n",
    "# Fit the BIRCH clustering model on the TF-IDF data\n",
    "birch_clustering.fit(X_subset)\n",
    "\n",
    "# Get the cluster labels for each data point\n",
    "labels = birch_clustering.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3862d3e-66e3-4f10-8799-4aeae487d24b",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a0c45b-41d7-4c60-97f6-5f32056956b6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.939619Z",
     "iopub.status.idle": "2023-04-29T19:59:36.940395Z",
     "shell.execute_reply": "2023-04-29T19:59:36.940101Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.940065Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(np.bincount(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0bba9-70cd-4e57-9d05-d6dda65b4d49",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.942304Z",
     "iopub.status.idle": "2023-04-29T19:59:36.942928Z",
     "shell.execute_reply": "2023-04-29T19:59:36.942642Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.942607Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 5000\n",
    "\n",
    "np.random.seed(24)\n",
    "\n",
    "random_indices = np.random.choice(\n",
    "    X_subset.shape[0], size=SAMPLE_SIZE, replace=False\n",
    ")  # Slice the sparse matrix using the generated indices\n",
    "\n",
    "\n",
    "X_sample_sparse = X_subset[random_indices]\n",
    "labels_sample = labels[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4764bb6-6f7d-43d4-a62a-e917459f987a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.944758Z",
     "iopub.status.idle": "2023-04-29T19:59:36.945527Z",
     "shell.execute_reply": "2023-04-29T19:59:36.945240Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.945205Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate Silhouette Score\n",
    "sil_score = silhouette_score(X_sample_sparse, labels_sample)\n",
    "\n",
    "# Calculate Calinski-Harabasz Index\n",
    "X_sample_dense = X_sample_sparse.toarray()\n",
    "ch_index = calinski_harabasz_score(X_sample_dense, labels_sample)\n",
    "\n",
    "# Calculate Davies-Bouldin Index\n",
    "db_index = davies_bouldin_score(X_sample_dense, labels_sample)\n",
    "\n",
    "# Print the scores\n",
    "print(\"Silhouette Score:\", sil_score)\n",
    "print(\"Calinski-Harabasz Index:\", ch_index)\n",
    "print(\"Davies-Bouldin Index:\", db_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41f66c-238e-4cb3-b38a-fe8f857c86b0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.947363Z",
     "iopub.status.idle": "2023-04-29T19:59:36.948143Z",
     "shell.execute_reply": "2023-04-29T19:59:36.947860Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.947826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len([node for node in birch_clustering.subcluster_centers_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac7f80-81fd-4490-9270-63a1432f3a39",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54991569-70fe-4aca-927c-76fe20088a29",
   "metadata": {},
   "source": [
    "### Levenshtein distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bfec4e-ea83-4893-9cb8-2e3d1be82919",
   "metadata": {},
   "source": [
    "#### Domain unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a955fb4-921a-4732-aeb9-32a3a7a33de4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.949721Z",
     "iopub.status.idle": "2023-04-29T19:59:36.950651Z",
     "shell.execute_reply": "2023-04-29T19:59:36.950348Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.950311Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create two sets of N_SAMPLES random samples\n",
    "N_SAMPLES = 50000\n",
    "\n",
    "urls_tsdf = pd.DataFrame()\n",
    "\n",
    "urls_tsdf[\"sample1\"] = urls_tdf.sample(n=N_SAMPLES, random_state=123).reset_index(\n",
    "    drop=True\n",
    ")[\"domain\"]\n",
    "urls_tsdf[\"sample2\"] = urls_tdf.sample(n=N_SAMPLES, random_state=545).reset_index(\n",
    "    drop=True\n",
    ")[\"domain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706cbc96-e309-47fd-b563-117a79b2dfc3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.952456Z",
     "iopub.status.idle": "2023-04-29T19:59:36.953065Z",
     "shell.execute_reply": "2023-04-29T19:59:36.952783Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.952748Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate Levenshtein distance on each pair (N_SAMPLES distances)\n",
    "urls_tsdf[\"levenshtein_distance_domain\"] = urls_tsdf.apply(\n",
    "    lambda row: levenshtein(row.sample1, row.sample2), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ed219-581e-4893-944b-34af308294bd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.954740Z",
     "iopub.status.idle": "2023-04-29T19:59:36.955609Z",
     "shell.execute_reply": "2023-04-29T19:59:36.955312Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.955277Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_tsdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a5f06-6df9-4db0-b8e2-af4b407e2610",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.957204Z",
     "iopub.status.idle": "2023-04-29T19:59:36.958108Z",
     "shell.execute_reply": "2023-04-29T19:59:36.957840Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.957806Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_tsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c18a9-080c-465b-af74-3ff9900f3b20",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.959532Z",
     "iopub.status.idle": "2023-04-29T19:59:36.960374Z",
     "shell.execute_reply": "2023-04-29T19:59:36.960096Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.960062Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    urls_tsdf,\n",
    "    x=\"levenshtein_distance_domain\",\n",
    "    binwidth=3,\n",
    "    height=10,\n",
    ")\n",
    "plt.title(\n",
    "    f\"Distribution of levenshtein's distances among domains over {N_SAMPLES} random samples\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745cafb-956c-4176-bf57-793032e538b8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.962224Z",
     "iopub.status.idle": "2023-04-29T19:59:36.962813Z",
     "shell.execute_reply": "2023-04-29T19:59:36.962527Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.962494Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    urls_tsdf[urls_tsdf[\"levenshtein_distance_domain\"] < 40],\n",
    "    x=\"levenshtein_distance_domain\",\n",
    "    binwidth=1,\n",
    "    height=8,\n",
    ")\n",
    "plt.title(\n",
    "    f\"Distribution of levenshtein's distances among domains over {N_SAMPLES} random samples\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ff443d-8f5c-4755-b499-9358aa916d15",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cdb219-22d8-4fce-9b1b-295c5a2fd40e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Unchanged URLs\n",
    "\n",
    "Keep `urls_tdf` intact for this section to show what it should"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6bf02f-5d5c-4350-af26-8262a2534122",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44239fe1-6d7e-40b1-a7b8-af7abd7b13b8",
   "metadata": {},
   "source": [
    "DBSCAN will not work. It needs $\\mathcal{O}(n^2)$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21e102d3-c00d-4ae7-8e3f-08500a1b8a47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T18:02:35.391999Z",
     "iopub.status.busy": "2023-03-01T18:02:35.391177Z"
    },
    "tags": []
   },
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# For more info on the trick refer to class definition\n",
    "string_trick = SklearnStringTrick(dataset=urls_tdf[\"url\"])\n",
    "\n",
    "unchanged_dbscan = DBSCAN(metric=string_trick.lev_dist_sklearn_urls)\n",
    "\n",
    "X = np.arange(len(string_trick.dataset)).reshape(-1, 1)\n",
    "\n",
    "out = unchanged_dbscan.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223500e-ef8b-4ff6-8aa2-09bee11688aa",
   "metadata": {},
   "source": [
    "#### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4802b5-1fc8-4829-bfea-097745aff773",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.966288Z",
     "iopub.status.idle": "2023-04-29T19:59:36.966955Z",
     "shell.execute_reply": "2023-04-29T19:59:36.966675Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.966641Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509d4ba-63b9-40a1-8eaa-a70f86087f65",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.968909Z",
     "iopub.status.idle": "2023-04-29T19:59:36.969463Z",
     "shell.execute_reply": "2023-04-29T19:59:36.969207Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.969176Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create two sets of N_SAMPLES random samples\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "urls_tsdf = urls_tdf.sample(n=N_SAMPLES, random_state=111).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a748b61-fa62-42aa-b3fd-e7c5a5493a59",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.971564Z",
     "iopub.status.idle": "2023-04-29T19:59:36.972220Z",
     "shell.execute_reply": "2023-04-29T19:59:36.971958Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.971925Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate pairwise distances between domains using levenshtein distance function\n",
    "X = urls_tsdf[\"domain\"].values.reshape(-1, 1)\n",
    "distances = pdist(X, metric=levenshtein_pdist)\n",
    "distances_squareform = squareform(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c42ac-c30b-459b-99cf-864e0b23ed1f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.974075Z",
     "iopub.status.idle": "2023-04-29T19:59:36.974746Z",
     "shell.execute_reply": "2023-04-29T19:59:36.974467Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.974435Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform hierarchical clustering\n",
    "Z = linkage(distances, \"complete\")\n",
    "\n",
    "# Draw dendrogram for visual cutoff selection\n",
    "fig, ax = plt.subplots(figsize=(40, 20))\n",
    "dendrogram(Z, ax=ax)\n",
    "\n",
    "\n",
    "fig1 = fig\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e826f-ee81-4a5c-a41a-053ee9107b80",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.976550Z",
     "iopub.status.idle": "2023-04-29T19:59:36.977138Z",
     "shell.execute_reply": "2023-04-29T19:59:36.976887Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.976844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CUTOFF = [42, 23, 19, 31]\n",
    "\n",
    "# Load the figure object from the previous cell\n",
    "fig = fig1\n",
    "\n",
    "# Get the axes object from the figure\n",
    "ax = fig.axes[0]\n",
    "\n",
    "# Add the cutoff horizontal line\n",
    "for cutoff in CUTOFF:\n",
    "    ax.axhline(y=cutoff, color=\"r\", linestyle=\"--\")\n",
    "    ax.text(x=ax.get_xlim()[0], y=cutoff, s=f\"Cutoff: {cutoff}\", va=\"center\")\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d1cac0-5af6-444c-a3ee-c5a7d0789634",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.979123Z",
     "iopub.status.idle": "2023-04-29T19:59:36.979992Z",
     "shell.execute_reply": "2023-04-29T19:59:36.979738Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.979705Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine the optimal number of clusters\n",
    "max_d = 15  # set the threshold distance\n",
    "clusters = fcluster(Z, max_d, criterion=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5299ce1f-3194-4462-85e4-91c115140fab",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.981557Z",
     "iopub.status.idle": "2023-04-29T19:59:36.982118Z",
     "shell.execute_reply": "2023-04-29T19:59:36.981867Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.981835Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add cluster labels to the original dataset\n",
    "urls_tsdf[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee40700-e32e-4827-9a63-7a5516e24ad0",
   "metadata": {},
   "source": [
    "#### Evaluation of cluster quality based on cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a53787a-baba-4ab5-a63d-3b9fe15bee9c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.983923Z",
     "iopub.status.idle": "2023-04-29T19:59:36.984790Z",
     "shell.execute_reply": "2023-04-29T19:59:36.984512Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.984479Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Compute the silhouette score\n",
    "silhouette_avg = silhouette_score(\n",
    "    distances_squareform, urls_tsdf[\"cluster\"], metric=\"precomputed\"\n",
    ")\n",
    "print(f\"Silhouette score: {silhouette_avg}\")\n",
    "\n",
    "# calculate prevalence of malicious domains in each cluster\n",
    "cluster_prevalence = urls_tsdf.groupby(\"cluster\")[\"malicious\"].mean()\n",
    "\n",
    "# group by cluster id and count the number of items in each cluster\n",
    "cluster_counts = urls_tsdf.groupby(\"cluster\").count()[\"url\"]\n",
    "\n",
    "# create a dataframe combining the cluster counts and cluster prevalence\n",
    "cluster_data = pd.DataFrame({\"count\": cluster_counts, \"prevalence\": cluster_prevalence})\n",
    "\n",
    "# filter perfect clusters\n",
    "non_trivial_clusters = cluster_data.loc[\n",
    "    (cluster_data[\"prevalence\"] != 0) & (cluster_data[\"prevalence\"] != 1)\n",
    "]\n",
    "\n",
    "print(f\"Total count of samples {len(urls_tsdf)}\")\n",
    "print(f\"Total count of clusters {len(cluster_data)}\")\n",
    "print(\n",
    "    f\"Count of samples in perfect clusters {len(urls_tsdf) - non_trivial_clusters['count'].sum()}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Prevalence of non-perfect malicious domains within clusters:\\n{non_trivial_clusters}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0242f1b1-c894-4c7e-b336-9e41cd94ac49",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.986545Z",
     "iopub.status.idle": "2023-04-29T19:59:36.987101Z",
     "shell.execute_reply": "2023-04-29T19:59:36.986853Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.986821Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reset the index to get the cluster id as a column\n",
    "cluster_data = cluster_data.reset_index()\n",
    "\n",
    "# Create color palette\n",
    "colors = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "# Create bar plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.barplot(\n",
    "    x=\"cluster\",\n",
    "    y=\"prevalence\",\n",
    "    data=cluster_data,\n",
    "    palette=colors(cluster_data[\"count\"] / cluster_data[\"count\"].max()),\n",
    "    ax=ax,\n",
    "    dodge=False,\n",
    ")\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_title(\"Prevalence of Malicious Domains by Cluster\")\n",
    "ax.set_xlabel(\"Cluster Number\")\n",
    "ax.set_ylabel(\"Prevalence\")\n",
    "\n",
    "# Move the legend outside the plot and make it a gradient line\n",
    "sm = plt.cm.ScalarMappable(\n",
    "    cmap=colors, norm=plt.Normalize(vmin=0, vmax=cluster_data[\"count\"].max())\n",
    ")\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(\n",
    "    sm,\n",
    "    orientation=\"horizontal\",\n",
    "    pad=0.1,\n",
    "    shrink=0.5,\n",
    "    aspect=15,\n",
    ")\n",
    "cbar.ax.set_xlabel(\"Cluster Size\")\n",
    "\n",
    "plt.subplots_adjust(right=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8a0c26b-5118-4a57-b2d8-a52c83b24ccc",
   "metadata": {},
   "source": [
    "TODO: Refactor into visualisation function\n",
    "TODO: Add leaving out trivial clusters\n",
    "TODO: Add number of clusters left out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98889a7-990f-4d4a-9c0e-77a331b9e4c3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.989033Z",
     "iopub.status.idle": "2023-04-29T19:59:36.989557Z",
     "shell.execute_reply": "2023-04-29T19:59:36.989315Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.989285Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_tsdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308112d9-9206-43a0-9093-3191188b54ce",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T19:59:36.991424Z",
     "iopub.status.idle": "2023-04-29T19:59:36.992030Z",
     "shell.execute_reply": "2023-04-29T19:59:36.991786Z",
     "shell.execute_reply.started": "2023-04-29T19:59:36.991755Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_tsdf.groupby(\"cluster\").count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor_kernel",
   "language": "python",
   "name": "bachelor_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
